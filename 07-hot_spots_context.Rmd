# Chapter 7: Understanding and interpreting hot spots of crime in context


## Crime concentration in micro places. 

In the previous chapter we introduced how to make sense of spatial point patterns, and isarithmic maps as a way to begin talking about crime concentration at micro places. However at the end of the chapter we raised some issues. For one, we mentioned that the maps show you *counts* of crime in a *smooth surface*. That sentence highlights two issues. *First:* by looking at counts, we are not controlling for the number of opportunities present. We discussed this at lenght when visualising crime in thematic maps - the importance of choosing an appropriate *denominator* which can be used to calculate crime rates, and avoid simply highlighting areas with high population as high crime areas. In the case of isarithmic maps this was not done. The *second* issue is that of calculating distances over a *smooth surface*. This approach does not reflect the routine activities of the individual actors involved in the creation (and blocking) of crime opportunities. For example, if we are moving around a city, we would use the street networks to get around.     

One way to address this issue is to consider examining our data using **micro-places** as our unit of analysis. This is suggested by @Chainey_2021 as an optimal way forward. They recommend considering street segments, street junctions, or micro grid cells as appropriate units of analyses, which may address some of the problems of heterogeneity and arbitrary borders, discussed in Chapter 4 under the topic of MAUP, as well as some of the problems with isarithmic maps outlined above. 


In this chapter we will cover some other ways to think about crime concentration in micro places by putting "hot spots" in context. Specifically we will explore the following: 

- visualising crime concentration at micro grid cells
- evaluating the presence of hot spots in the micro grid cells using Getis Ord statistic
- joining crime data to street segment (or in this case, underground line segment)
- joining crime data to street junction (or in this case underground station)
- demonstrate the importance of considering context when finding hotspots
- evaluating crime concentration in these types of micro places using Gini coefficient and Lorenz curve
- an alternatice (non-spatial) way to visualise crime along a network - using **street profile analysis**


```{r}

library(readr)
library(janitor)
library(sf)
library(rnaturalearth)
library(dplyr)
```

```{r}

btp_crimes <- read_csv("data/btp_crimes_2019.csv") %>% clean_names()

btp_crimes <- st_as_sf(btp_crimes, coords = c("longitude", "latitude"), 
                 crs = 4326, agr = "constant")

ldn <- ne_states(country = "united kingdom", returnclass = "sf") %>% filter(grepl("London", type_en) & name != "Derry") %>% st_transform(4326)

plot(st_geometry(btp_crimes))
plot(st_geometry(ldn),  add = TRUE)


```


## Micro Grid Cells

In chapter 4 we discussed alternatives to our choropleth maps, and one of these was to use a grid map. This is a process whereby a tessalating grid of a shape such as squares or hexagons is overlaid on top of our area of interest, and our points are aggregated to such a grid. 


@Chainey_2021 recommend


We explored this using `ggplot2` package. Here we can revisit this with another approach, using the `raster` package: 

```{r}
library(raster)


pixelsize <-  0.01
box <-  (extent(ldn) / pixelsize) * pixelsize
template = raster(box, crs = 4326,
	nrows = (box@ymax - box@ymin) / pixelsize, 
	ncols = (box@xmax - box@xmin) / pixelsize)

btp_crimes$PRESENT <-  1
btp_crimes_raster <- rasterize(btp_crimes, template, field = 'PRESENT', fun = sum)

plot(btp_crimes_raster)
plot(st_geometry(ldn), border='#00000040', add=T)
```



We can make this more accessible for the analyst to explore, for example by overlaying on a leaflet map, like we did with KDE map in the previous chapter. 

```{r, warning=FALSE, message=FALSE}
library(leaflet)

pal <- colorNumeric(c("#0C2C84", "#41B6C4", "#FFFFCC"), values(btp_crimes_raster),
  na.color = "transparent")

leaflet() %>% 
  addTiles() %>%
  addRasterImage(btp_crimes_raster, colors = pal, opacity = 0.8) %>%
  addLegend(pal = pal, values = values(btp_crimes_raster),
    title = "BTP Crimes")


```


## Getis-Ord GI*

One major issue with the above, which is another issue associated with kernel density estimation is that the choice of a threshold for what is and is not a hot spot is arbitrary, making use of KDE imprecise and subject to misinterpretation.

One commonly used technique to work around that issues was developed by Arthur Getis and JK Ord in the early 1990s. When you develop an algorithm, you get to name it after yourself, so this is called the Getis-Ord GI* statistic.

This statistic is based on the observation that the distribution of differences in crime intensity between neighbouring areas across a map will follow a normal curve. Therefore, the amount of difference between an area and its neighbors can then be converted to a z-score reflecting the number of standard deviations (Ïƒ) that the crime level in an area differs from neighborhood normal. Areas with high z-scores (indicating a crime significantly above the mean) are identified as hot spots, while areas with low z-scores are identified as cold spots.

```{r}



getisgrid <-  rasterToPolygons(btp_crimes_raster)

# Create the list of neighbors

library(spdep)
neighbors <-  poly2nb(getisgrid)
weighted_neighbors = nb2listw(neighbors, zero.policy=T)

# Perform the local G analysis (Getis-Ord GI*)

getisgrid$HOTSPOT = as.vector(localG(getisgrid$layer, weighted_neighbors))

# Color the grid cells based on the z-score

breaks = quantile(getisgrid$HOTSPOT, na.rm = TRUE)
palette=c("#0000FF80", "#8080FF80", "#FFFFFF80", "#FF808080", "#FF000080")
col = palette[cut(getisgrid$HOTSPOT, breaks)]

# Plot

plot(getisgrid, col=col, border=NA)
plot(st_geometry(ldn), border="gray", add=T)

```

Or on a leaflet map to aid interpretation: 

```{r}

pal <- colorQuantile(c("#0000FF80", "#8080FF80", "#FFFFFF80", "#FF808080", "#FF000080"),getisgrid$HOTSPOT, 
  na.color = "transparent")

leaflet(getisgrid) %>% 
  addTiles() %>%
  addPolygons(fillColor =  ~pal(HOTSPOT), fillOpacity = 0.8, weight = 0) %>% 
  addLegend(pal = pal, values = ~HOTSPOT, opacity = 0.7, 
            title = 'BTP crimes')

```


## Spatial point patterns along networks

Another approach is to assign the crimes to some meaningful micro-place, such as a street segment, or street junction. This is recommended by @Chainey_2021. It is not only in the case of street networks that understanding spatial point patterns along a network might be more meaningful, there are other networks we might want to consider. 

For example, with the British Transport Police data we are working, we can actually understand our crimes to have happened on or around the London Underground network. That is what we will illustrate these processes with here.

London Underground is made up of 11 lines and 380 stops along its network. We can acquire data from the TfL Open API, whereby you can query for each individual line. If you are interested, see the [TfL API](). For simplicity sake I've saved this all in a geojson file. 

## 2 Maybe add the bit that Chainey covers in new book (step by step computation of measures of crime concentration using Weisburd criteria)?

## 3 Lorens and Gini curves to look at concentration?

## 1 Spatial point patterns along networks

Have a look at this maps.  Can we say that the spatial point process is random here? Can you identify the areas where we have hotspots of crime? Think about these questions for a little while.

![](img/nonrandompoints.png)
(Source: Okabe and Sugihara, 2012)

Ok, so most likely you concluded that the process wasn't random, which it isn't in truth. It is also likely that you identified a number of potential hotspots?

Now, look at the two maps below:

![](img/randompoints.png)
(Source: Okabe and Sugihara, 2012)

We are representing the same spatial point pattern process in each of them. But we do have additional information in map B. We now know the street layout. The structure we observed in the map is accounted by the street layout. So what look like a non random spatial point process when we considered the full two dimensional space, now looks less random when we realise that the points can only appear alongside the linear network. 

This problem is common in criminal justice applications. Crime is geocoded alongside a linear street network. Even if in physical space crime can take place along a spatial continuum, once crime is geocoded it will only be possible alongside the street network used for the geocoding process. 

For exploring this kind of spatial point pattern processes along networks we need special techniques. Some researchers have developed special applications, such as [SANET](http://sanet.csis.u-tokyo.ac.jp/sub_en/manual.html). The `spatstat` package also provides some functionality for this kind of data structures.

In `spatstat` a point pattern on a linear network is represented by an object of class `lpp`. The functions `lpp()` and `as.lpp()` convert raw data into an object of class `lpp` (but they require a specification of the underlying network of lines, which is represented by an object of class `linnet`). For simplicity and illustration purposes we will use the `chicago` dataset that is distributed as part of the `spatstat` package. The `chicago` data is of class `lpp` and contains information on crime in an area of Chicago. 

```{r}
data("chicago")
plot(chicago)
summary(chicago)
```

An `lpp` object contains the linear network information, the spatial coordinates of the data points, and any number of columns of *marks* (in this case the mark is telling us the type of crime we are dealing with). It also contains the local coordinates `seg` and `tp` for the data points. The local coordinate `seg` is an integer identifying the particular street segment the data point is located in. A segment is each of the sections of a street between two vertices (marking the intersection with another segment). The local coordinate `tp` is a real number between 0 and 1 indicating the position of the point within the segement: `tp=0` corresponds to the first endpoint and `tp=1` correspond to the second endpoint.

The visual inspection of the map suggest that the intensity of crime along the network is not spatially uniform. Crime seems to be concentrated in particular segments. Like we did before we can estimate the density of data points along the networks using Kernel estimation (with the `density.lpp()` function), only now we only look at the street segments (rather than areas of the space that are outside the segments). The authors of the package are planning to introduce methods for automatic bandwidth selection but for now this is not possible, so we have to select a bandwidth. We could for example select 60 feet.

```{r}
d60 <- density.lpp(unmark(chicago), 60)
```

We use `unmark()` to ignore the fact the data points are marked (that is they provide marks with informtation, in this case about the crime type). By using `unmark()` in this example we will run density estimation for all crimes (rather than by type of crime). We can see the results below:
 
```{r}
plot(d60)
```
 
If rather than colour you want to use the thickness of the street segment to identify hotpspots you would need to modify the code as shown below:
 
```{r}
plot(d60, style="width", adjust=2.5)
```



This is very important for crime research, as offending will be constrained by all sorts of networks. Traditionally, hotspot analysis has been directed at crimes that are assumed to be situated across an infinite homogeneous environment (e.g., theft of motor vehicle), we must develop an increased awareness of perceptible geographical restrictions. There has been increasing recognition in recent years that the spatial existence of many phenomena is constrained by networks. 

These networks may be roads or rail networks, but there may be many more: 

> Environmental crimes could exist along waterways such as streams, canals, and rivers; and thefts of metal could occur along utility networks such as pipelines. Those
sociologically inclined might be able to offer more examples in the way of interpersonal networks. 

- [Tompson, Lisa, Henry Partridge, and Naomi Shepherd. "Hot routes: Developing a new technique for the spatial analysis of crime." Crime Mapping: A Journal of Research and Practice 1, no. 1 (2009): 77-96.](http://discovery.ucl.ac.uk/20057/)


While sometimes there may be issues with linking points to routes due to problems such as bad geocoding, as we had discusses in great detail in week 4, there are obivious advantages to considering crime as distributed along networks, rather than continuous space. 
